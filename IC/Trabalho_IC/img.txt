Vinição:
-----------------------------------------------------------------

*** CONFUSION MATRIX ***

Scores actual (rows) vs predicted (columns):

7×7 Matrix{Any}:
 "Labels"     "0"     "1"     "2"     "3"     "4"     "5"
 "0"       262      14      11      27      44      79
 "1"        25     368       2       7       5      67
 "2"        12       2     373      82      67      17
 "3"        14       2      59     389      55       6
 "4"        25       5      54      62     353      11
 "5"        64      22      14      12      14     375
Normalised scores actual (rows) vs predicted (columns):

7×7 Matrix{Any}:
 "Labels"   "0"        "1"         "2"         "3"        "4"        "5"
 "0"       0.599542   0.0320366   0.0251716   0.0617849  0.100686   0.180778
 "1"       0.0527426  0.776371    0.00421941  0.0147679  0.0105485  0.14135
 "2"       0.0216998  0.00361664  0.674503    0.148282   0.121157   0.0307414
 "3"       0.0266667  0.00380952  0.112381    0.740952   0.104762   0.0114286
 "4"       0.0490196  0.00980392  0.105882    0.121569   0.692157   0.0215686
 "5"       0.127745   0.0439122   0.0279441   0.0239521  0.0279441  0.748503

 *** CONFUSION REPORT ***

- Accuracy:               0.7066666666666667
- Misclassification rate: 0.29333333333333333
- Number of classes:      6

  N Class   precision   recall  specificity  f1score  actual_count  predicted_count
                          TPR       TNR                 support

  1 0           0.652    0.600        0.945    0.625          437             402
  2 1           0.891    0.776        0.982    0.830          474             413
  3 2           0.727    0.675        0.943    0.700          553             513
  4 3           0.672    0.741        0.923    0.705          525             579
  5 4           0.656    0.692        0.926    0.674          510             538
  6 5           0.676    0.749        0.928    0.710          501             555

- Simple   avg.    0.712    0.705        0.941    0.707
- Weigthed avg.    0.712    0.707        0.941    0.708

-----------------------------------------------------------------
Output of `info(cm)`:
- mean_precision:       (0.7122559151363376, 0.711703416795929)
- fitted_records:       3000
- specificity:  [0.9453765119001171, 0.982185273159145, 0.9427870862280343, 0.9232323232323232, 0.9257028112449799, 0.9279711884753902]
- precision:    [0.6517412935323383, 0.8910411622276029, 0.7270955165692008, 0.6718480138169257, 0.6561338289962825, 0.6756756756756757]
- misclassification:    0.29333333333333333
- mean_recall:  (0.7053380987166397, 0.7066666666666667)
- n_categories: 6
- normalised_scores:    [0.5995423340961098 0.032036613272311214 0.02517162471395881 0.06178489702517163 0.10068649885583524 0.18077803203661327; 0.052742616033755275 0.7763713080168776 0.004219409282700422 0.014767932489451477 0.010548523206751054 0.14135021097046413; 0.0216998191681736 0.003616636528028933 0.674502712477396 0.14828209764918626 0.12115732368896925 0.03074141048824593; 0.02666666666666667 0.0038095238095238095 0.11238095238095239 0.7409523809523809 0.10476190476190476 0.011428571428571429; 0.049019607843137254 0.00980392156862745 0.10588235294117647 0.12156862745098039 0.692156862745098 0.021568627450980392; 0.1277445109780439 0.043912175648702596 0.027944111776447105 0.023952095808383235 0.027944111776447105 0.7485029940119761]
- tn:   [2423, 2481, 2307, 2285, 2305, 2319]
- mean_f1score: (0.7071217014606043, 0.7075330322956466)
- actual_count: [437, 474, 553, 525, 510, 501]
- accuracy:     0.7066666666666667
- recall:       [0.5995423340961098, 0.7763713080168776, 0.674502712477396, 0.7409523809523809, 0.692156862745098, 0.7485029940119761]
- f1score:      [0.6245530393325387, 0.8297632468996617, 0.699812382739212, 0.7047101449275363, 0.6736641221374046, 0.7102272727272727]
- mean_specificity:     (0.9412091990399983, 0.9405885275733229)
- predicted_count:      [402, 413, 513, 579, 538, 555]
- scores:       [262 14 11 27 44 79; 25 368 2 7 5 67; 12 2 373 82 67 17; 14 2 59 389 55 6; 25 5 54 62 353 11; 64 22 14 12 14 375]
- tp:   [262, 368, 373, 389, 353, 375]
- fn:   [175, 106, 180, 136, 157, 126]
- categories:   [0, 1, 2, 3, 4, 5]
- fp:   [140, 45, 140, 190, 185, 180]



Prof:
-----------------------------------------------------------------

*** CONFUSION MATRIX ***

Scores actual (rows) vs predicted (columns):

7×7 Matrix{Any}:
 "Labels"     "0"     "1"     "2"     "3"     "4"     "5"
 "0"       204      45      35      50      40      63
 "1"        14     408       2      10       3      37
 "2"         2       3     417      68      54       9
 "3"         4       4      70     385      58       4
 "4"        15      10      94      72     313       6
 "5"        60      49      31      18      15     328
Normalised scores actual (rows) vs predicted (columns):

7×7 Matrix{Any}:
 "Labels"   "0"         "1"         "2"         "3"        "4"         "5"
 "0"       0.466819    0.102975    0.0800915   0.114416   0.0915332   0.144165
 "1"       0.0295359   0.860759    0.00421941  0.021097   0.00632911  0.0780591
 "2"       0.00361664  0.00542495  0.754069    0.122966   0.0976492   0.0162749
 "3"       0.00761905  0.00761905  0.133333    0.733333   0.110476    0.00761905
 "4"       0.0294118   0.0196078   0.184314    0.141176   0.613725    0.0117647
 "5"       0.11976     0.0978044   0.0618762   0.0359281  0.0299401   0.654691

 *** CONFUSION REPORT ***

- Accuracy:               0.685
- Misclassification rate: 0.31499999999999995
- Number of classes:      6

  N Class   precision   recall  specificity  f1score  actual_count  predicted_count
                          TPR       TNR                 support

  1 0           0.682    0.467        0.963    0.554          437             299
  2 1           0.786    0.861        0.956    0.822          474             519
  3 2           0.643    0.754        0.905    0.694          553             649
  4 3           0.638    0.733        0.912    0.683          525             603
  5 4           0.648    0.614        0.932    0.630          510             483
  6 5           0.734    0.655        0.952    0.692          501             447

- Simple   avg.    0.689    0.681        0.937    0.679
- Weigthed avg.    0.686    0.685        0.935    0.681

-----------------------------------------------------------------
Output of `info(cm)`:
- mean_precision:       (0.6885360936322779, 0.6864718651571796)
- fitted_records:       3000
- specificity:  [0.962934061646508, 0.9560570071258907, 0.9051900286064569, 0.9119191919191919, 0.9317269076305221, 0.9523809523809523]
- precision:    [0.6822742474916388, 0.7861271676300579, 0.6425269645608629, 0.6384742951907131, 0.6480331262939959, 0.7337807606263982]
- misclassification:    0.31499999999999995
- mean_recall:  (0.6805661456707949, 0.685)
- n_categories: 6
- normalised_scores:    [0.4668192219679634 0.10297482837528604 0.08009153318077804 0.11441647597254005 0.09153318077803203 0.14416475972540047; 0.029535864978902954 0.8607594936708861 0.004219409282700422 0.02109704641350211 0.006329113924050633 0.07805907172995781; 0.003616636528028933 0.0054249547920434 0.7540687160940326 0.12296564195298372 0.09764918625678119 0.0162748643761302; 0.007619047619047619 0.007619047619047619 0.13333333333333333 0.7333333333333333 0.11047619047619048 0.007619047619047619; 0.029411764705882353 0.0196078431372549 0.1843137254901961 0.1411764705882353 0.6137254901960785 0.011764705882352941; 0.11976047904191617 0.09780439121756487 0.06187624750499002 0.03592814371257485 0.029940119760479042 0.654690618762475]
- tn:   [2468, 2415, 2215, 2257, 2320, 2380]
- mean_f1score: (0.6791606353379391, 0.6806759531340134)
- actual_count: [437, 474, 553, 525, 510, 501]
- accuracy:     0.685
- recall:       [0.4668192219679634, 0.8607594936708861, 0.7540687160940326, 0.7333333333333333, 0.6137254901960785, 0.654690618762475]
- f1score:      [0.5543478260869565, 0.8217522658610272, 0.6938435940099834, 0.6826241134751773, 0.6304128902316214, 0.6919831223628692]
- mean_specificity:     (0.9367013582182536, 0.935208149309522)
- predicted_count:      [299, 519, 649, 603, 483, 447]
- scores:       [204 45 35 50 40 63; 14 408 2 10 3 37; 2 3 417 68 54 9; 4 4 70 385 58 4; 15 10 94 72 313 6; 60 49 31 18 15 328]
- tp:   [204, 408, 417, 385, 313, 328]
- fn:   [233, 66, 136, 140, 197, 173]
- categories:   [0, 1, 2, 3, 4, 5]
- fp:   [95, 111, 232, 218, 170, 119]


- Perera
-----------------------------------------------------------------

*** CONFUSION MATRIX ***

Scores actual (rows) vs predicted (columns):

7×7 Matrix{Any}:
 "Labels"     "0"     "1"     "2"     "3"     "4"     "5"
 "0"       256      28      25      29      57      42
 "1"        39     396       0       6       9      24
 "2"        10       3     370      54     103      13
 "3"        15       4      56     331     115       4
 "4"        23      12      58      38     372       7
 "5"        89      34      21      13      36     308
Normalised scores actual (rows) vs predicted (columns):

7×7 Matrix{Any}:
 "Labels"   "0"        "1"         "2"        "3"        "4"        "5"
 "0"       0.585812   0.0640732   0.0572082  0.0663616  0.130435   0.0961098
 "1"       0.0822785  0.835443    0.0        0.0126582  0.0189873  0.0506329
 "2"       0.0180832  0.00542495  0.669078   0.0976492  0.186257   0.0235081
 "3"       0.0285714  0.00761905  0.106667   0.630476   0.219048   0.00761905
 "4"       0.045098   0.0235294   0.113725   0.0745098  0.729412   0.0137255
 "5"       0.177645   0.0678643   0.0419162  0.0259481  0.0718563  0.61477

 *** CONFUSION REPORT ***

- Accuracy:               0.6776666666666666
- Misclassification rate: 0.32233333333333336
- Number of classes:      6

  N Class   precision   recall  specificity  f1score  actual_count  predicted_count
                          TPR       TNR                 support

  1 0           0.593    0.586        0.931    0.589          437             432
  2 1           0.830    0.835        0.968    0.833          474             477
  3 2           0.698    0.669        0.935    0.683          553             530
  4 3           0.703    0.630        0.943    0.665          525             471
  5 4           0.538    0.729        0.871    0.619          510             692
  6 5           0.774    0.615        0.964    0.685          501             398

- Simple   avg.    0.689    0.677        0.935    0.679
- Weigthed avg.    0.690    0.678        0.935    0.679

-----------------------------------------------------------------
Output of `info(cm)`:
- mean_precision:       (0.689182694229944, 0.6897828125697832)
- fitted_records:       3000
- specificity:  [0.9313304721030042, 0.9679334916864608, 0.9346138128320393, 0.9434343434343434, 0.8714859437751004, 0.963985594237695]
- precision:    [0.5925925925925926, 0.8301886792452831, 0.6981132075471698, 0.70276008492569, 0.5375722543352601, 0.7738693467336684]
- misclassification:    0.32233333333333336
- mean_recall:  (0.6774985944838917, 0.6776666666666666)
- n_categories: 6
- normalised_scores:    [0.585812356979405 0.06407322654462243 0.057208237986270026 0.06636155606407322 0.13043478260869565 0.09610983981693363; 0.08227848101265822 0.8354430379746836 0.0 0.012658227848101266 0.0189873417721519 0.05063291139240506; 0.018083182640144666 0.0054249547920434 0.6690777576853526 0.09764918625678119 0.18625678119349007 0.023508137432188065; 0.02857142857142857 0.007619047619047619 0.10666666666666667 0.6304761904761905 0.21904761904761905 0.007619047619047619; 0.045098039215686274 0.023529411764705882 0.11372549019607843 0.07450980392156863 0.7294117647058823 0.013725490196078431; 0.17764471057884232 0.06786427145708583 0.041916167664670656 0.02594810379241517 0.0718562874251497 0.6147704590818364]
- tn:   [2387, 2445, 2287, 2335, 2170, 2409]
- mean_f1score: (0.679018418325911, 0.679329768785849)
- actual_count: [437, 474, 553, 525, 510, 501]
- accuracy:     0.6776666666666666
- recall:       [0.585812356979405, 0.8354430379746836, 0.6690777576853526, 0.6304761904761905, 0.7294117647058823, 0.6147704590818364]
- f1score:      [0.5891829689298044, 0.832807570977918, 0.6832871652816251, 0.6646586345381527, 0.6189683860232945, 0.6852057842046718]
- mean_specificity:     (0.9354639430114404, 0.9351169914019766)
- predicted_count:      [432, 477, 530, 471, 692, 398]
- scores:       [256 28 25 29 57 42; 39 396 0 6 9 24; 10 3 370 54 103 13; 15 4 56 331 115 4; 23 12 58 38 372 7; 89 34 21 13 36 308]
- tp:   [256, 396, 370, 331, 372, 308]
- fn:   [181, 78, 183, 194, 138, 193]
- categories:   [0, 1, 2, 3, 4, 5]
- fp:   [176, 81, 160, 140, 320, 90]
